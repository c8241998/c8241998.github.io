---
title: 'ActivityNet Challenge 2019 冠军模型BMN算法全解析'
date: 2020-05-27
permalink: /posts/2020/05/blog-post-1/
tags:
  - temporal action detection
  - computer vision
  - deep learning
---

随着互联网世界视频数量的急剧增长，视频内容分析技术得到了越来越广泛关注。视频动作定位是视频内容分析领域里的一个重要任务，它的目标是在一段未经修剪的视频中定位出动作类别及其对应的时序边界。通常视频动作定位任务可以分为两个阶段：时序提名生成和动作分类。本文所介绍的算法BMN为百度自研，为时序提名生成任务提供了一个高效的解决方案，是ActivityNet2019大赛中的task1和task2的冠军方案（task1为时序提名生成，task2为视频动作定位）。

模型概览
======

**BMN算法概览：**  
<img src="/images/1/1.jpg" width="40%"/>

**网络配置图：**  
<img src="/images/1/2.png" width="40%"/>

<figure class="half">
    <img src="/images/1/1.jpg" width="40%">
    <img src="/images/1/2.png" width="40%">
</figure>

作为BSN系列的改进方案，BMN算法继承了BSN的整体思路：先定位动作的边界，再将边界节点组合为时序提名，对于候选的时序提名，基于置信度分数进行筛选，得到最终的动作定位集合。  
BMN模型的处理流程如下：首先使用双流网络（光流+RGB）对输入视频进行预处理，得到编码特征。然后将编码特征输入Base Module，使用两层时序卷积提取特征，其后分TEM和PEM两个分支进行处理，TEM模块通过两层时序卷积处理得到视频每个位置为开始边界的概率序列和为结束边界的概率序列，PEM模块处理得到BM配置信度图（该过程将在下文中详细介绍），使用该置信度图可以轻松得到任一候选提名的置信度分数。  
在后处理阶段，边界概率两个序列中的极大值点及超过最大值一半的点所在视频位置被视为候选开始边界或候选结束边界。通过对两种边界的两两组合，我们可以得到一系列的候选动作提名，再通过在置信度图中检索分数，我们可以得到一个拥有置信度分数的候选提名集合。最后，算法采用了Soft-NMS方法来去除了冗余结果。  


You can have many headings
======

Aren't headings cool?
------
