---
title: 'ActivityNet Challenge 2019 冠军模型BMN算法全解析'
date: 2020-05-27
permalink: /posts/2020/05/blog-post-1/
tags:
  - temporal action detection
  - computer vision
  - deep learning
---

随着互联网世界视频数量的急剧增长，视频内容分析技术得到了越来越广泛关注。视频动作定位是视频内容分析领域里的一个重要任务，它的目标是在一段未经修剪的视频中定位出动作类别及其对应的时序边界。通常视频动作定位任务可以分为两个阶段：时序提名生成和动作分类。本文所介绍的算法BMN为百度自研，为时序提名生成任务提供了一个高效的解决方案，是ActivityNet2019大赛中的task1和task2的冠军方案（task1为时序提名生成，task2为视频动作定位）。

模型概览
======

<figure class="half" align=center>
    <img src="/images/1/1.jpg" width="40%" alt="BMN算法概览">
    <img src="/images/1/2.png" width="40%" alt="网络配置图">
</figure>

作为BSN系列的改进方案，BMN算法继承了BSN的整体思路：先定位动作的边界，再将边界节点组合为时序提名，对于候选的时序提名，基于置信度分数进行筛选，得到最终的动作定位集合。  
BMN模型的处理流程如下：首先使用双流网络（光流+RGB）对输入视频进行预处理，得到编码特征。然后将编码特征输入Base Module，使用两层时序卷积提取特征，其后分TEM和PEM两个分支进行处理，TEM模块通过两层时序卷积处理得到视频每个位置为开始边界的概率序列和为结束边界的概率序列，PEM模块处理得到BM配置信度图（该过程将在下文中详细介绍），使用该置信度图可以轻松得到任一候选提名的置信度分数。  
在后处理阶段，边界概率两个序列中的极大值点及超过最大值一半的点所在视频位置被视为候选开始边界或候选结束边界。通过对两种边界的两两组合，我们可以得到一系列的候选动作提名，再通过在置信度图中检索分数，我们可以得到一个拥有置信度分数的候选提名集合。最后，算法采用了Soft-NMS方法来去除了冗余结果。  

边界匹配机制
======

BMN提出了一种新的时序提名置信度评估机制——边界匹配机制，作用于PEM模块。边界匹配机制的目的是为生成的候选提名提出可靠的置信度分数，下面笔者将从以下三个方面对该机制进行讲解。

BM置信度图
------

首先我们将一个时序动作提名$\phi$表示为开始边界为t_S，结束边界为 $t_e$ 的匹配对。如下图所示，边界匹配机制的目的是创建由有不同开始边界和长度的边界匹配对组成的二维BM置信度图M_C。我们用M_C\left(i,j\right)表示提名\varphi\left(i,j\right)的置信度分数，其中\varphi\left(i,j\right)的开始边界t_s=t_j，持续时长d=t_i，因此其结束边界t_e=t_j+t_i。因此，我们可以使用BM置信度图来为候选的时序提名获取置信度分数。
