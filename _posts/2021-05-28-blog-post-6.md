---
title: 'Image Classification Based on Few-Shot Learning'
date: 2021-05-28
permalink: /posts/2021/05/blog-post-6/
tags:
  - Few-shot learning
  - computer vision
  - deep learning
---

This blog classifies and summarizes the current image classification algorithms based on Few-shot learning. According to the modeling methods of different data types, Few-shot image classification algorithms are divided into convolution neural network model and graph neural network model. Convolution neural network model is divided into four learning paradigms: transfer learning, meta learning, Bayesian learning and dual learning. Two kinds of algorithms are introduced in detail. Finally, for the current Few-shot image classification algorithm, we discuss the ethical oriented implications in terms of interpretability and privacy.

# Introduction

## Background

Image classification is a hot research topic. Typical image classification algorithms involve two problems, one is how to better represent image features, and the other is how to learn good model parameters. With the development of deeper design of convolutional neural networks (CNN), the representation ability of image features becomes stronger and stronger. Before CNN was born, researchers extracted image features through artificially designed image features, such as Scale-invariant feature transform(SIFT) [1], Histogram of oriented gradient (HOG) [2], Bag-of-words (BoW) [3], etc, However, they are usually hard to design and not general. CNN based deep learning model has achieved great success in 2012 ILSVRC challenge. At the same time, with the development of computing hardware and optimizing algorithm, deep learning has achieved excellent performance in image classification [4].

Driven by data, the model can learn effectively. However, a small dataset will lead to over fitting problems. Simple data augmentation (DA) and regularization can alleviate the problem, but it has not been completely solved [5]. In 2003, Li et al. proposed One-shot learning problem for the first time and used Bayesian framework [6] to learn visual objects. Compared with it, deep learning algorithms can achieves better in the small sample image classification. There are two factors for the emergence of Few-shot learning, One is the small amount of training data. For example, in the medical field, medical images are generated from cases, but a small number of cases can not support a deep algorithm. The other is to make the machine learn to learn in the human way. Human can learn to classify and recognize samples given a small number of examples, and has the ability to quickly understand new concepts and generalize them [6]. Few-shot learning has been applied in many image processing tasks, such as object recognition, semantic segmentation, image retrieval. Researches [7][8] discuss and analyze Few-shot learning from different perspectives, such as the number of samples, the number of labeled samples, the prior knowledge, etc.

From 2010 to 2015, a large number of researches used semantic transfer to solve the problem of insufficient training samples. For example, Mensink et al. [9] used clustering and metric learning methods to classify ImageNet datasets, and explored KNN (k-nearest neighbor) and NCM (Nearest class mean) classifiers to learn a metric through the semantic feature of each class. It can be shared between training and testing categories to achieve the transfer; In [10], semantic knowledge transfer is extended to transductive inference, which uses known categories to infer the representation of unknown categories, calculates the sample similarity of unknown categories, projects the data into a low dimensional semantic space when constructing the spatial distribution of data, and further finds the spatial distribution of the data. Good classification results are obtained on AwA (Animals with attributes) [11], ImageNet and MPII composites activities; In [12], a transductive multi-view embedding framework was proposed to solve the problem of domain shift, and heterogeneous multi-view label propagation was used to solve the problem of sparsity. The complementary information provided by different semantic representations was effectively used, and good results were achieved on the datasets of AwA, CUB (Caltech-UCSD-Birds) [13] and USAA (Unstructured social activity attribute) [14]; In order to solve the problem of attribute learning of social media data with sparse and incomplete labels, Fu et al. \cite{fu2013learning} proposed a model of learning semi latent attribute space by using the idea of zero sample learning, which can express user-defined and potential attribute information, and achieved good results on USAA datasets. These papers mainly focus on Zero-shot learning. However, this blog aims to introduce the image classification algorithms based on small samples, so it is more focused on the Few-shot learning.

In recent years, the existing image classification algorithms based on few-shot learning are mainly based on deep learning. Several methods are used, such as data augmentation to increase the number of samples, extracting image features through attention mechanism and memory mechanism, and designing the mapping relationship between feature network and classifier. Transfer learning, meta learning, dual learning, Bayesian learning and graph neural network (GNN) are also used in the task of Few-shot image classification. The Few-shot learning algorithm described in this blog is designed for image classification task. The algorithms in [7][8] are applied to not only image classification, but also image tasks such as recognition and segmentation, as well as voice and video tasks. Firstly, this blog focuses on the Few-shot image classification algorithms and summarizes them. Secondly, this blog explores different methods, and divides them into CNN model and GNN model.

## Problem definition

### Dataset processing

### Feature extraction

### Classifier

## Dataset and evaluation metrics

### Public dataset

### Evaluation Metrics

# Few-shot image classification algorithms

## Transfer learning

### Feature based Transfer learning

### Correlation based Transfer learning

### Shared Parameter based Transfer learning

## Meta learning

### Metric based meta learning

### Model based meta learning

### Optimization based meta learning

# Ethical oriented implications

## Interpretability

## Privacy

### Differential privacy

### Homomorphic encryption

# Conclusion





# References

[1] Yu-Gang Jiang, Jingen Liu, A Roshan Zamir, George Toderici, Ivan Laptev, Mubarak Shah,and Rahul Sukthankar. Thumos challenge: Action recognition with a large number of classes,2014.

[2] Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos Niebles. Activ-itynet: A large-scale video benchmark for human activity understanding. InProceedings ofthe ieee conference on computer vision and pattern recognition, pages 961–970, 2015.

[3] Zheng Shou, Dongang Wang, and Shih-Fu Chang. Temporal action localization in untrimmedvideos via multi-stage cnns. InProceedings of the IEEE Conference on Computer Vision andPattern Recognition, pages 1049–1058, 2016.

[4] Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, and Dahua Lin. Temporalaction detection with structured segment networks. InProceedings of the IEEE InternationalConference on Computer Vision, pages 2914–2923, 2017.

[5] Tianwei Lin, Xu Zhao, and Zheng Shou. Single shot temporal action detection. InProceedingsof the 25th ACM international conference on Multimedia, pages 988–996, 2017.2


[6] Shyamal Buch, Victor Escorcia, Bernard Ghanem, Li Fei-Fei, and Juan Carlos Niebles. End-to-end, single-stream temporal action detection in untrimmed videos. 2019.

[7] Shyamal Buch, Victor Escorcia, Chuanqi Shen, Bernard Ghanem, and Juan Carlos Niebles.Sst:  Single-stream temporal action proposals.  InProceedings of the IEEE conference onComputer Vision and Pattern Recognition, pages 2911–2920, 2017.

[8] Fabian Caba Heilbron, Juan Carlos Niebles, and Bernard Ghanem. Fast temporal activityproposals for efficient detection of human actions in untrimmed videos. InProceedings of theIEEE conference on computer vision and pattern recognition, pages 1914–1923, 2016.

[9] Victor Escorcia, Fabian Caba Heilbron, Juan Carlos Niebles, and Bernard Ghanem. Daps:Deep action proposals for action understanding. InEuropean Conference on Computer Vision,pages 768–784. Springer, 2016.

[10] Jiyang Gao, Zhenheng Yang, Kan Chen, Chen Sun, and Ram Nevatia. Turn tap: Temporalunit regression network for temporal action proposals. InProceedings of the IEEE internationalconference on computer vision, pages 3628–3636, 2017.

[11] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang.  Bsn: Boundarysensitive network for temporal action proposal generation. InProceedings of the EuropeanConference on Computer Vision (ECCV), pages 3–19, 2018.

[12] Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. Bmn: Boundary-matching networkfor temporal action proposal generation. InProceedings of the IEEE International Conferenceon Computer Vision, pages 3889–3898, 2019.

[13] Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method fordeep neural networks. InWorkshop on challenges in representation learning, ICML, volume 3,2013.

[14] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V. Le.  Self-training with noisystudent improves imagenet classification, 2020.

[15] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning, 2017.

[16] Takeru Miyato, Shin ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial train-ing: A regularization method for supervised and semi-supervised learning, 2018.

[17] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and ColinRaffel. Mixmatch: A holistic approach to semi-supervised learning, 2019.

[18] Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D.Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel. Fixmatch: Simplifying semi-supervisedlearning with consistency and confidence, 2020.

[19] Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and LucVan Gool. Temporal segment networks: Towards good practices for deep action recognition.InEuropean conference on computer vision, pages 20–36. Springer, 2016.

[20] Colin Lea, Michael D Flynn, Rene Vidal, Austin Reiter, and Gregory D Hager. Temporalconvolutional networks for action segmentation and detection.  Inproceedings of the IEEEConference on Computer Vision and Pattern Recognition, pages 156–165, 
